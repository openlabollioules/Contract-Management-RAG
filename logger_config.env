# Les Logger
### Fichier main.py
LOG_FILE_main="./Logs/main.log"
LOG_LEVEL_main="DEBUG"

### Fichier pdf_preparation.py
LOG_FILE_pdf_preparation="./Logs/pdf_preparation.log"
LOG_LEVEL_pdf_preparation="DEBUG"

### Fichier rag/hierarchical_grouper.py
LOG_FILE_hierarchical_grouper="./Logs/hierarchical_grouper.log"
LOG_LEVEL_hierarchical_grouper="DEBUG"

### Fichier rag/chunk_optimizer.py
LOG_FILE_chunk_optimizer="./Logs/chunk_optimizer.log"
LOG_LEVEL_chunk_optimizer="DEBUG"

### Fichier rag/semantic_chunker.py
LOG_FILE_semantic_chunker="./Logs/semantic_chunker.log"
LOG_LEVEL_semantic_chunker="DEBUG"

### Fichier rag/embeddings_manager.py
LOG_FILE_embeddings_manager="./Logs/embeddings_manager.log"
LOG_LEVEL_embeddings_manager="DEBUG"

### Fichier rag/retriever.py
LOG_FILE_retriever="./Logs/retriever.log"
LOG_LEVEL_retriever="DEBUG"

### Fichier rag/ollama_chat.py
LOG_FILE_ollama_chat="./Logs/ollama_chat.log"
LOG_LEVEL_ollama_chat="DEBUG"

### Fichier rag/ollama_manager.py
LOG_FILE_ollama_manager="./Logs/ollama_manager.log"
LOG_LEVEL_ollama_manager="DEBUG"

### Fichier rag/pdf_loader.py
LOG_FILE_pdf_loader="./Logs/pdf_loader.log"
LOG_LEVEL_pdf_loader="DEBUG"

### Fichier rag/chat_manager.py
LOG_FILE_chat_manager="./Logs/chat_manager.log"
LOG_LEVEL_chat_manager="DEBUG"

### Fichier rag/chroma_manager.py
LOG_FILE_chroma_manager="./Logs/chroma_manager.log"
LOG_LEVEL_chroma_manager="DEBUG"

### Fichier rag/intelligent_splitter.py
LOG_FILE_intelligent_splitter="./Logs/intelligent_splitter.log"
LOG_LEVEL_intelligent_splitter="DEBUG"

### Fichier scripts/download_models.py
LOG_FILE_download_models="./Logs/download_models.log" 
LOG_LEVEL_download_models="DEBUG"

### Fichier scripts/download_signature_model.py
LOG_FILE_download_signature_model="./Logs/download_signature_model.log"
LOG_LEVEL_download_signature_model="DEBUG"

### Fichier scripts/download_nltk_models.py
LOG_FILE_download_nltk_models="./Logs/download_nltk_models.log"
LOG_LEVEL_download_nltk_models="DEBUG"

### Fichier scripts/download_marker_models.py
LOG_FILE_download_marker_models="./Logs/download_marker_models.log"
LOG_LEVEL_download_marker_models="DEBUG"

### Ollama Environment
#OLLAMA_URL="http://host.docker.internal:11434/api/embeddings" #Mode Pipeline
OLLAMA_URL="http://localhost:11434/api/embeddings" #Mode Terminal 
# AI Models Configuration
LLM_MODEL="mistral-small3.1:latest"  # Default LLM model
#LLM_MODEL="qwen3:30b-a3b"
EMBEDDING_MODEL="BAAI/bge-m3"  # Default embedding model
TOP_K=8
TEMPERATURE=0.3
SIMILARITY_THRESHOLD=0.6
USE_OFFLINE_MODELS="false"

# Ollama Configuration
OLLAMA_URL="http://localhost:11434"  # Base Ollama URL (without /api/embeddings suffix)

# Paths Configuration
CACHE_DIR="offline_models/embeddings_cache"  # Cache directory for embeddings
MODELS_DIR="offline_models/hf"  # Base models directory
MARKER_DIR="offline_models/marker"  # Marker models directory
EMBEDDINGS_DIR="offline_models/embeddings"  # Embeddings models directory

# Hardware Configuration
USE_MPS=true  # Use MPS on Apple Silicon if available
USE_HALF_PRECISION=true  # Use FP16 for better performance on MPS/CUDA 
import os
import sys
import json
import time
import logging
import threading
from pathlib import Path
from dataclasses import dataclass, asdict
from datetime import datetime
from itertools import product
from typing import List, Dict, Optional, Any, Tuple
import concurrent.futures
import numpy as np
import pandas as pd
from tqdm import tqdm

# Add src directory to Python path
src_dir = Path(__file__).resolve().parent.parent
sys.path.append(str(src_dir))

from core.document_manager import cleanup_flag_documents
from core.chunk_summarizer import ChunkSummarizer
from document_processing.text_vectorizer import TextVectorizer
from document_processing.vectordb_interface import VectorDBInterface
from document_processing.llm_chat import LLMChat
from document_processing.text_chunker import TextChunker
from document_processing.reranker import Reranker
from core.graph_manager import GraphManager
from core.interaction import load_or_build_graph, get_graph_augmented_results, merge_results
from document_processing.pdf_extractor import extract_pdf_text
from utils.logger import setup_logger

# Configure logger
logger = setup_logger(__file__)

# Test questions and expected answers
TEST_CASES = [
    {
        "question": "Peux-tu m'indiquer les dates clÃ©s du Contrat A ?",
        "expected_answer": """
        Voici les dates clÃ©s du Contrat A prÃ©sent dans le fichier :
        â€¢ Date de signature du contrat : 20 mars 2012.
        â€¢ Date de commencement des travaux : correspond Ã  la date de signature, soit le 20 mars 2012.
        â€¢ DÃ©lai de 30 jours aprÃ¨s le dÃ©but du contrat : pÃ©riode prÃ©vue pour remplir certaines conditions supplÃ©mentaires.
        â€¢ DÃ©lais de livraison : prÃ©cisÃ©s dans l'Annexe 2 ("Delivery Schedule") pour chaque composant et document critique.
        â€¢ DÃ©lai d'approbation des documents : 15 jours pour retour du client, 10 jours pour resoumission aprÃ¨s commentaires.
        """
    },
    {
        "question": "Peux-tu me lister les Ã©lÃ©ments du contrat A qui impliquent le paiement potentiel d'indemnitÃ©s ou de pÃ©nalitÃ©s de la part du fournisseur ?",
        "expected_answer": """
        Voici les Ã©lÃ©ments du Contrat A qui impliquent un paiement potentiel d'indemnitÃ©s ou de pÃ©nalitÃ©s par le fournisseur :
        1. Retard de livraison d'Ã©quipement :
        â€¢ Des pÃ©nalitÃ©s journaliÃ¨res ("Equipment Delay Liquidated Damages") sont appliquÃ©es si le fournisseur dÃ©passe les dÃ©lais de livraison contractuels :
        â€¢ 0,03 % du prix du composant/jour pendant le 1er mois,
        â€¢ 0,04 % pendant le 2e mois,
        â€¢ 0,05 % Ã  partir du 3e mois.
        â€¢ Ces pÃ©nalitÃ©s sont plafonnÃ©es Ã  10 % du prix du composant concernÃ©.
        2. Retard dans la remise de documentation critique :
        â€¢ PÃ©nalitÃ©s de 500 â‚¬ par document et par semaine de retard,
        â€¢ Plafond global fixÃ© Ã  2 % du prix de l'unitÃ© concernÃ©e.
        3. Non-respect des garanties de performance :
        â€¢ Des pÃ©nalitÃ©s peuvent s'appliquer si les performances garanties ne sont pas atteintes et que cela entraÃ®ne une demande du client final, sauf si la cause est externe au fournisseur.
        4. Indemnisation pour dommages :
        â€¢ Le fournisseur est responsable des dommages causÃ©s par des dÃ©fauts de conception, fabrication ou nÃ©gligence,
        â€¢ Il couvre Ã©galement les rÃ©clamations liÃ©es Ã  des violations de droits de propriÃ©tÃ© intellectuelle.
        5. DÃ©fauts non corrigÃ©s :
        â€¢ En cas de dÃ©faut non rÃ©parÃ© dans un dÃ©lai raisonnable aprÃ¨s notification Ã©crite, le client peut faire exÃ©cuter les rÃ©parations par un tiers aux frais du fournisseur.
        6. RÃ©siliation pour retard :
        â€¢ Si le fournisseur atteint le plafond des pÃ©nalitÃ©s pour retard et ne respecte pas un dÃ©lai de livraison additionnel, le contrat peut Ãªtre rÃ©siliÃ© unilatÃ©ralement par le client.
        """
    },
    {
        "question": "Dans le contrat A, quelle est la clause qui est la plus problÃ©matique du point de vue du fournisseur et pourquoi ?",
        "expected_answer": """
        La clause la plus problÃ©matique pour le fournisseur dans le Contrat A est probablement la suivante :

        âš ï¸ Clause 11 : PÃ©nalitÃ©s de Retard sur Livraison d'Ã‰quipement
        ðŸ“Œ Pourquoi cette clause est problÃ©matique :
            â€¢ Cumul des pÃ©nalitÃ©s : Jusqu'Ã  0,05 %/jour Ã  partir du 3e mois de retard.
            â€¢ Plafond Ã©levÃ© : PlafonnÃ© Ã  10 % du prix de chaque composant.
            â€¢ Application automatique : Sans obligation de dÃ©monstration d'un prÃ©judice rÃ©el de la part de l'acheteur.
            â€¢ PÃ©nalitÃ©s cumulables avec d'autres types de pÃ©nalitÃ©s (ex. : documentation, performance) â€“ ce qui peut gÃ©nÃ©rer une charge financiÃ¨re importante.

        ðŸŽ¯ Risques concrets pour le fournisseur :
            â€¢ Un simple retard logistique ou administratif peut entraÃ®ner des pÃ©nalitÃ©s disproportionnÃ©es.
            â€¢ Aucune clause de grÃ¢ce, de mise en demeure prÃ©alable ni de prise en compte de circonstances attÃ©nuantes (hors force majeure explicite).
        """
    },
    {
        "question": "Dans le contrat A, quel est le risque de change introduit par le fait qu'une partie des prix soient Ã©tablis en roubles ?",
        "expected_answer": """
        Le Contrat A introduit un risque de change important du fait qu'une partie des prix soit libellÃ©e en roubles russes (RUB), comme cela est mentionnÃ© Ã  l'article 7.1, qui distingue :
            â€¢ une partie du prix en euros (EUR), et
            â€¢ une partie du prix en roubles (RUB).

        âš ï¸ Nature du risque de change pour le fournisseur :
            1. VolatilitÃ© du rouble : Le rouble est une monnaie soumise Ã  une forte instabilitÃ© politique et Ã©conomique. Sa valeur peut fluctuer brutalement, notamment en raison de :
                â—¦ sanctions internationales,
                â—¦ instabilitÃ©s macroÃ©conomiques,
                â—¦ dÃ©cisions monÃ©taires unilatÃ©rales de la Russie.
            2. Risque de perte de marge : Si le fournisseur supporte des coÃ»ts en euros ou dollars mais facture en roubles, une dÃ©prÃ©ciation du rouble entre la signature et le paiement rÃ©duira significativement la valeur rÃ©elle perÃ§ue.
            3. Absence apparente de clause d'ajustement : Le contrat ne semble pas comporter de mÃ©canisme de couverture ou d'indexation en cas de variation du taux de change, ce qui laisse le fournisseur totalement exposÃ©.
        """
    },
    {
        "question": "Quelles sont les lois applicables mentionnÃ©es dans le contrat A ?",
        "expected_answer": """
        Le Contrat A prÃ©cise la loi applicable dans l'article 24.1, comme suit :
        âš–ï¸ Loi applicable :
        Le contrat est rÃ©gi par le droit matÃ©riel suisse, Ã  l'exclusion de ses rÃ¨gles de conflit de lois.
        La Convention de Vienne de 1980 sur la vente internationale de marchandises ne s'applique pas.
        
        ðŸ§‘â€âš–ï¸ RÃ¨glement des litiges (Article 24.2) :
        â€¢ En cas de litige non rÃ©solu Ã  l'amiable :
        â€¢ Il sera soumis Ã  l'arbitrage selon les rÃ¨gles de la Chambre de commerce internationale (CCI).
        â€¢ L'arbitrage se tiendra Ã  GenÃ¨ve, en langue anglaise.
        â€¢ La dÃ©cision arbitrale est finale et contraignante pour les deux parties
        """
    },
    {
        "question": "A partir du contrat A, peux-tu dresser la liste des actions Ã  mener par le fournisseur en termes de documents Ã  fournir au client ?",
        "expected_answer": """
        Voici la liste des actions documentaires Ã  mener par le fournisseur selon le Contrat A, ainsi que leurs modalitÃ©s :
        ðŸ“‹ 1. Livrables documentaires identifiÃ©s dans l'Annexe 2
        â€¢ Le fournisseur doit fournir tous les documents listÃ©s dans l'Exhibit 2 ("Document Delivery Schedule").
        â€¢ Cela inclut des documents techniques, qualitÃ©, essais, manuels de montage, mise en service, maintenance, etc.

        ðŸ“ 2. Documentation nÃ©cessitant validation du client
        â€¢ Certains documents nÃ©cessitent revue, approbation ou acceptation du client. Cela est Ã©galement spÃ©cifiÃ© dans l'Exhibit 2.
        â€¢ Le client doit retourner les documents sous 15 jours avec commentaires.
        â€¢ Le fournisseur doit soumettre une version corrigÃ©e sous 10 jours.

        ðŸ·ï¸ 3. Format, codification et transmission
        â€¢ Le format, codification, mÃ©thode d'envoi sont prÃ©cisÃ©s dans un Supplementary Agreement Ã  conclure dans les 90 jours suivant la signature.

        âš ï¸ 4. Documentation critique
        â€¢ Toute "Critical Documentation" doit Ãªtre livrÃ©e aux dates de l'Exhibit 2.
        â€¢ En cas de retard, des pÃ©nalitÃ©s de 500 â‚¬ par document/semaine peuvent Ãªtre appliquÃ©es, plafonnÃ©es Ã  2 % du prix de l'unitÃ©.

        ðŸŒ 5. Langue
        â€¢ Toute la documentation doit Ãªtre fournie en anglais.

        ðŸš¨ 6. Correction des dÃ©fauts
        â€¢ En cas de dÃ©faut ou d'omission dans un document, le client peut exiger une correction immÃ©diate et diligente.
        """
    },
    {
        "question": "Quelles obligations du contrat A doivent Ãªtre impÃ©rativement intÃ©grÃ©es aux contrats qu'ALSTOM signera avec ses fournisseurs ou sous-traitants ?",
        "expected_answer": """
        Voici les obligations du Contrat A qui doivent impÃ©rativement Ãªtre rÃ©percutÃ©es par ALSTOM dans ses contrats avec ses fournisseurs et sous-traitants (obligations dites "flow-down") :

        ðŸ” 1. Engagements de confidentialitÃ©
        â€¢ Clause trÃ¨s stricte imposant la confidentialitÃ© pour une durÃ©e de 10 ans aprÃ¨s divulgation.
        â€¢ Toute sous-traitance impliquant l'accÃ¨s Ã  des informations sensibles doit Ãªtre encadrÃ©e par des engagements similaires.

        ðŸ“„ 2. Livraison de documentation critique
        â€¢ Le fournisseur principal est responsable de livrer les documents critiques Ã  des dates fixes sous peine de pÃ©nalitÃ©s de 500 â‚¬/document/semaine, plafonnÃ©es Ã  2 % du prix de l'unitÃ©.
        â€¢ Ces Ã©chÃ©ances doivent Ãªtre transmises aux sous-traitants avec engagement contractuel ferme sur le respect des dates.

        â±ï¸ 3. DÃ©lais de livraison et pÃ©nalitÃ©s
        â€¢ Retards sur les composants entraÃ®nent des pÃ©nalitÃ©s croissantes (jusqu'Ã  0,05 %/jour) avec un plafond de 10 % du prix du composant.
        â€¢ Les sous-traitants livrant des composants critiques doivent se voir imposer des pÃ©nalitÃ©s similaires pour permettre au fournisseur principal de se retourner contre eux si besoin.

        âš™ï¸ 4. Garantie / responsabilitÃ© pour dÃ©fauts
        â€¢ Obligation pour le fournisseur de rÃ©parer ou remplacer les composants dÃ©fectueux pendant la pÃ©riode de garantie (jusqu'Ã  24 mois aprÃ¨s acceptation).
        â€¢ ALSTOM doit s'assurer que ses fournisseurs offrent une garantie Ã©quivalente, avec droits de recours en cas de dÃ©faillance.

        ðŸ›‘ 5. Clause de non-responsabilitÃ© du client pour l'installation
        â€¢ Le Contrat A prÃ©cise que le fournisseur ne sera pas tenu responsable des dÃ©fauts liÃ©s Ã  l'installation faite par des tiers. Si ALSTOM sous-traite l'installation, elle doit s'assurer que les responsabilitÃ©s sont contractuellement bien rÃ©parties entre les acteurs concernÃ©s.

        ðŸ”„ 6. Garanties bancaires
        â€¢ Obligation de fournir :
        â€¢ Garantie de remboursement d'acompte (100 % APBG),
        â€¢ Garantie de bonne exÃ©cution (5 % PBG),
        â€¢ DÃ©lai prÃ©cis de remise (20 jours aprÃ¨s dÃ©marrage).
        â€¢ Ces exigences doivent Ãªtre imposÃ©es aux fournisseurs ou bancarisÃ©es Ã  leur nom, si nÃ©cessaire.

        ðŸ“¦ 7. Obligations en cas de rÃ©siliation
        â€¢ En cas de rÃ©siliation du contrat principal, ALSTOM peut devoir interrompre, transfÃ©rer ou rÃ©clamer le matÃ©riel et les prestations.
        â€¢ Elle doit prÃ©voir des clauses de transfert de propriÃ©tÃ© anticipÃ©e et de continuitÃ© avec ses fournisseurs pour couvrir ce risque.
        """
    }
]

@dataclass(frozen=True)
class Config:
    model: str
    rerank_model: Optional[str]
    top_k: int
    temperature: float
    similarity_threshold: float
    use_summarize: bool
    chat_mode: str

class RAGBenchmark:
    def __init__(self, test_cases: List[Dict[str, Any]]):
        self.test_cases = test_cases
        self.configs = [Config(m, r, k, t, s, u, c)
                        for m, r, k, t, s, u, c in product(
                            ["command-a:latest"],
                            [None, "bge-reranker-large", "Jina-ColBERT-v1"],
                            [3, 5, 7, 10],
                            [0.1, 0.3, 0.5, 0.7],
                            [0.5, 0.6, 0.7, 0.8],
                            [True],
                            ["graph"]
                        )]
        self.workspace_dir = Path(__file__).resolve().parent.parent
        self.contract_dir = self.workspace_dir / ".." / "data" / "Contract"
        
        # Modification - Utiliser le chemin absolu de la DB Ã  la racine du projet
        project_root = self.workspace_dir.parent  # Remonte d'un niveau pour atteindre le rÃ©pertoire racine
        self.db_dir = project_root / "chroma_db"
        logger.info(f"Utilisation de la base de donnÃ©es Ã : {self.db_dir}")
        
        self._verify_paths()

        # Initialize caches and components
        self.text_cache: Dict[Path, str] = {}
        self.chunk_cache: Dict[Path, Any] = {}
        self.text_vectorizer = TextVectorizer()
        self.chunker = TextChunker()
        self.summarizer = ChunkSummarizer()
        self.rerankers: Dict[str, Reranker] = {}
        # Cache keyed by summarization flag only
        self.db_cache: Dict[bool, Tuple[VectorDBInterface, Any]] = {}

        self.results: List[Dict[str, Any]] = []
        self.results_lock = threading.Lock()
        self.analysis_event = threading.Event()

        self._prepare_result_files()
        self._init_rerankers()
        self._connect_to_database()

        # Start periodic analysis thread
        self.analysis_thread = threading.Thread(target=self._periodic_analysis)
        self.analysis_thread.daemon = True
        self.analysis_thread.start()

    def _verify_paths(self):
        if not self.contract_dir.exists():
            raise FileNotFoundError(f"Contract directory not found: {self.contract_dir}")
        files = [f for f in self.contract_dir.iterdir() if f.suffix.lower() in {'.pdf', '.doc', '.docx'}]
        if not files:
            raise FileNotFoundError("No supported files found in contract directory")
        logger.info(f"Found {len(files)} contract files.")
        
        if not self.db_dir.exists():
            logger.warning(f"Database directory not found: {self.db_dir}. Running in read-only mode with existing database.")

    def _prepare_result_files(self):
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.results_dir = self.workspace_dir / "benchmark_results"
        self.results_dir.mkdir(exist_ok=True)
        self.json_file = self.results_dir / f"results_{timestamp}.json"
        self.analysis_file = self.results_dir / f"analysis_{timestamp}.md"
        self.excel_file = self.results_dir / f"detailed_{timestamp}.xlsx"
        with open(self.json_file, 'w', encoding='utf-8') as f:
            json.dump([], f)
        with open(self.analysis_file, 'w', encoding='utf-8') as f:
            f.write(f"# RAG Benchmark Analysis\nDate: {datetime.now()}\n")

    def _init_rerankers(self):
        for cfg in self.configs:
            key = cfg.rerank_model
            if key and key not in self.rerankers:
                try:
                    self.rerankers[key] = Reranker(key)
                    logger.info(f"Loaded reranker: {key}")
                except Exception as e:
                    logger.warning(f"Skipping reranker {key}: {e}")

    def _extract_text(self, file_path: Path) -> str:
        if file_path not in self.text_cache:
            suffix = file_path.suffix.lower()
            if suffix == '.pdf':
                text, _ = extract_pdf_text(file_path)
            else:
                from document_processing.doc_reader import extract_doc_text
                text, _ = extract_doc_text(file_path)
            self.text_cache[file_path] = text
        return self.text_cache[file_path]

    def _get_chunks(self, file_path: Path) -> Any:
        if file_path not in self.chunk_cache:
            text = self._extract_text(file_path)
            chunks = self.chunker.chunk_text(text, str(file_path))
            self.chunk_cache[file_path] = chunks
        return self.chunk_cache[file_path]

    def _connect_to_database(self):
        """Connect to existing database in read-only mode without resetting or modifying it."""
        logger.info(f"Connecting to existing database at: {self.db_dir}")
        
        # CrÃ©ation d'une seule instance de ChromaDB
        import chromadb
        try:
            # CrÃ©er une seule instance du client ChromaDB
            chroma_client = chromadb.PersistentClient(
                path=str(self.db_dir),
                settings=chromadb.config.Settings(
                    anonymized_telemetry=False,
                    allow_reset=False,  # Mode lecture seule
                    is_persistent=True
                )
            )
            
            # Lister les collections disponibles - ChromaDB 0.6.0 retourne directement les noms
            try:
                collection_names = chroma_client.list_collections()
                logger.info(f"Collections existantes dans la base: {collection_names}")
            except Exception as e:
                logger.error(f"Erreur lors de la rÃ©cupÃ©ration des collections: {e}")
                # Essai direct avec la collection "contracts"
                collection_names = ["contracts"]
            
            # Adapter notre classe VectorDBInterface pour utiliser le client existant
            class ReadOnlyVectorDBInterface:
                def __init__(self, client, collection_name, text_vectorizer):
                    self.collection = client.get_collection(collection_name)
                    self.embeddings_manager = text_vectorizer
                
                def search(self, query, n_results=5, filter_metadata=None):
                    logger.info(f"Recherche dans ChromaDB: '{query}' (n_results={n_results})")
                    query_embedding = self.embeddings_manager.get_embeddings([query])[0]
                    results = self.collection.query(
                        query_embeddings=[query_embedding],
                        n_results=n_results * 2,
                        where=filter_metadata,
                    )
                    
                    formatted_results = []
                    seen_originals = set()
                    
                    for i in range(len(results["ids"][0])):
                        metadata = results["metadatas"][0][i]
                        is_summary = metadata.get("is_summary", "false").lower() == "true"
                        original_content = metadata.get("original_content", "")
                        
                        if is_summary:
                            result = {
                                "id": results["ids"][0][i],
                                "document": results["documents"][0][i],
                                "metadata": metadata,
                                "distance": results["distances"][0][i],
                                "is_summary": True,
                                "original_content": original_content
                            }
                            formatted_results.append(result)
                            seen_originals.add(original_content)
                        elif results["documents"][0][i] not in seen_originals:
                            result = {
                                "id": results["ids"][0][i],
                                "document": results["documents"][0][i],
                                "metadata": metadata,
                                "distance": results["distances"][0][i],
                                "is_summary": False
                            }
                            formatted_results.append(result)
                            
                    formatted_results.sort(key=lambda x: x["distance"])
                    return formatted_results[:n_results]
            
            # Si aucune collection n'est trouvÃ©e, essayons d'utiliser collection_names[0]
            if not collection_names:
                raise RuntimeError("Aucune collection n'existe dans la base de donnÃ©es")
            
            # Pour chaque configuration, utiliser la premiÃ¨re collection disponible
            for use_sum in {cfg.use_summarize for cfg in self.configs}:
                if use_sum in self.db_cache:
                    continue
                
                try:
                    # Utiliser la premiÃ¨re collection disponible
                    collection_name = collection_names[0]
                    logger.info(f"Utilisation de la collection: {collection_name}")
                    
                    # CrÃ©er notre wrapper de vectordb avec le client existant
                    db = ReadOnlyVectorDBInterface(chroma_client, collection_name, self.text_vectorizer)
                    
                    # Valider que la collection contient des documents
                    results = db.search("test", n_results=1)
                    if not results:
                        logger.warning(f"Collection '{collection_name}' est vide")
                        continue
                    
                    # Tenter de charger le graphe depuis le fichier
                    graph_path = self.workspace_dir.parent / "knowledge_graph.pkl"
                    if graph_path.exists():
                        try:
                            # Charger directement avec pickle
                            import pickle
                            logger.info(f"Chargement du graphe depuis: {graph_path}")
                            with open(str(graph_path), 'rb') as f:
                                graph = pickle.load(f)
                                if graph:
                                    logger.info(f"Graphe chargÃ© avec succÃ¨s depuis: {graph_path}")
                                    self.db_cache[use_sum] = (db, graph)
                                    logger.info(f"Base de donnÃ©es et graphe chargÃ©s avec succÃ¨s pour use_summarize={use_sum}")
                                    continue
                        except Exception as e:
                            logger.warning(f"Ã‰chec du chargement du graphe: {e}")
                    
                    # Si nous sommes arrivÃ©s ici, c'est que nous n'avons pas pu charger le graphe
                    # On va charger le graphe plus simplement avec la fonction existante
                    try:
                        from core.interaction import load_or_build_graph
                        logger.info("Utilisation de load_or_build_graph")
                        graph = load_or_build_graph(db, self.text_vectorizer)
                        if graph:
                            self.db_cache[use_sum] = (db, graph)
                            logger.info(f"Graphe chargÃ©/construit avec succÃ¨s pour use_summarize={use_sum}")
                            continue
                        else:
                            logger.warning("Ã‰chec de load_or_build_graph - graphe vide ou nul")
                    except Exception as e:
                        logger.warning(f"Ã‰chec de load_or_build_graph: {e}")
                
                except Exception as e:
                    logger.warning(f"Ã‰chec avec la collection '{collection_name}': {e}")
            
            # VÃ©rifier si nous avons rÃ©ussi Ã  configurer au moins une base de donnÃ©es
            if not self.db_cache:
                raise RuntimeError("Impossible de se connecter Ã  une base de donnÃ©es valide")
                
        except Exception as e:
            logger.error(f"Erreur de connexion Ã  la base de donnÃ©es: {e}")
            raise RuntimeError(f"Impossible de se connecter Ã  une base de donnÃ©es valide: {e}")

    def _build_prompt(self, context: List[str], question: str) -> str:
        ctx = '\n\n---\n\n'.join(context) if context else 'Aucun contexte pertinent trouvÃ©.'
        return f"Tu es un assistant spÃ©cialisÃ© dans l'analyse de contrats.\nContexte:\n{ctx}\nQuestion: {question}\nRÃ©ponse:"

    def _calculate_metrics(self, answer: str, expected: str) -> Dict[str, float]:
        # keyword accuracy
        terms = set(expected.lower().split())
        found = sum(1 for t in terms if t in answer.lower())
        acc = found/len(terms) if terms else 0.0
        # semantic similarity using cached embeddings
        emb_ans = self.text_vectorizer.get_embeddings([answer])[0]
        emb_exp = self.text_vectorizer.get_embeddings([expected])[0]
        sim = float(np.dot(emb_ans, emb_exp)/(np.linalg.norm(emb_ans)*np.linalg.norm(emb_exp))) if np.linalg.norm(emb_ans) and np.linalg.norm(emb_exp) else 0.0
        return {'accuracy': acc, 'semantic_sim': sim}

    def _run_single(self, cfg: Config, case: Dict[str, Any]) -> None:
        res = {'config': asdict(cfg), 'question': case['question'], 'response_time': None, 'accuracy': None, 'semantic_sim': None}
        try:
            db, graph = self.db_cache[cfg.use_summarize]
            results = db.search(query=case['question'], n_results=cfg.top_k)
            filtered = [d for d in results if d['distance'] <= 1-cfg.similarity_threshold]
            if cfg.chat_mode=='graph':
                aug = get_graph_augmented_results(graph, filtered)
                docs = merge_results(filtered, aug)
            else:
                docs = filtered
            context = [d['document'] for d in docs]
            if cfg.rerank_model and cfg.rerank_model in self.rerankers:
                context = self.rerankers[cfg.rerank_model].rerank(case['question'], context, cfg.top_k)
            llm = LLMChat(model=cfg.model)
            prompt = self._build_prompt(context, case['question'])
            t0 = time.time()
            ans = llm.generate(prompt, options={'temperature':cfg.temperature})
            t1 = time.time()
            metrics = self._calculate_metrics(ans, case['expected_answer'])
            res.update({'answer': ans, 'response_time': t1-t0, **metrics})
        except Exception as e:
            logger.exception("Error in run_single")
            res['error'] = str(e)
        with self.results_lock:
            self.results.append(res)
            with open(self.json_file, 'w', encoding='utf-8') as f:
                json.dump(self.results, f, ensure_ascii=False, indent=2)


    def _periodic_analysis(self):
        while not self.analysis_event.wait(timeout=60):
            self._write_analysis()
        # un dernier dump Ã  la fin
        self._write_analysis()

    def _write_analysis(self):
        # Use raw DataFrame to preserve 'config' column
        df = pd.DataFrame(self.results)
        with open(self.analysis_file, 'w', encoding='utf-8') as f:
            f.write(f"# Analysis Update: {datetime.now()}\n")
            f.write(f"Total runs: {len(self.results)}\n")
            # Fastest run
            if 'response_time' in df.columns and not df['response_time'].isna().all():
                idx = df['response_time'].idxmin()
                best = df.iloc[idx]
                f.write(f"**Fastest run**: {best['config']} in {best['response_time']:.2f}s\n")
            # Best semantic similarity
            if 'semantic_sim' in df.columns and not df['semantic_sim'].isna().all():
                idx2 = df['semantic_sim'].idxmax()
                bests = df.iloc[idx2]
                f.write(f"**Best semantic sim**: {bests['config']} = {bests['semantic_sim']:.3f}\n")
        with pd.ExcelWriter(self.excel_file) as writer:
            df.to_excel(writer, index=False)

    def run(self):
        print("ðŸš€ Starting RAG benchmark...")
        tasks = [(cfg, case) for cfg in self.configs for case in self.test_cases]
        # On soumet tout et on garde la correspondance futureâ†’(cfg,case)
        with concurrent.futures.ThreadPoolExecutor(max_workers=os.cpu_count() or 4) as executor:
            future_to_task = {
                executor.submit(self._run_single, cfg, case): (cfg, case)
                for cfg, case in tasks
            }
            # on crÃ©e une barre tqdm
            with tqdm(total=len(future_to_task), desc="Benchmarking") as pbar:
                for future in concurrent.futures.as_completed(future_to_task):
                    cfg, case = future_to_task[future]
                    try:
                        future.result()
                    except Exception as e:
                        logger.error(f"Erreur sur {cfg}, question Â«{case['question']}Â» : {e}")
                    # On met Ã  jour la barre avec la combo terminÃ©e
                    pbar.set_postfix({
                        "model": cfg.model,
                        "top_k": cfg.top_k,
                        "question": case["question"][:30] + "â€¦"
                    })
                    pbar.update()
        # on arrÃªte proprement le thread pÃ©riodique
        self.analysis_event.set()
        self.analysis_thread.join()
        print("âœ… Benchmark complete.")

if __name__ == '__main__':
    cleanup_flag_documents()
    benchmark = RAGBenchmark(TEST_CASES)
    benchmark.run()

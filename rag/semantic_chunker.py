from typing import List, Optional

from langchain_experimental.text_splitter import SemanticChunker
from sentence_transformers import SentenceTransformer
from langchain_core.embeddings import HuggingFaceEmbeddings

from .intelligent_splitter import Chunk


class SemanticChunkManager:
    """
    GÃ¨re le chunking sÃ©mantique des textes, en respectant les structures hiÃ©rarchiques des contrats juridiques.
    
    Utilise le SemanticChunker de langchain_experimental pour regrouper les parties de texte
    sÃ©mantiquement proches, tout en prÃ©servant les frontiÃ¨res de sections importantes.
    """
    
    def __init__(
        self,
        embedding_model_name: str = "sentence-transformers/all-MiniLM-L6-v2",
        breakpoint_threshold: float = 0.25,
        min_chunk_size: int = 100,
        max_chunk_size: int = 2000
    ):
        """
        Initialise le manager de chunking sÃ©mantique.
        
        Args:
            embedding_model_name: Nom du modÃ¨le d'embeddings Ã  utiliser
            breakpoint_threshold: Seuil de dissimilaritÃ© pour crÃ©er une rupture entre chunks (plus Ã©levÃ© = moins de ruptures)
            min_chunk_size: Taille minimale d'un chunk en caractÃ¨res
            max_chunk_size: Taille maximale d'un chunk en caractÃ¨res
        """
        # Initialiser les embeddings HuggingFace pour le chunker
        self.embedding_model = HuggingFaceEmbeddings(model_name=embedding_model_name)
        
        # Initialiser le chunker sÃ©mantique
        self.semantic_chunker = SemanticChunker(
            embeddings=self.embedding_model,
            breakpoint_threshold=breakpoint_threshold,
            min_chunk_size=min_chunk_size,
            max_chunk_size=max_chunk_size
        )
        
    def _preprocess_text_with_section_markers(self, text: str) -> str:
        """
        PrÃ©traite le texte en ajoutant des marqueurs spÃ©ciaux aux dÃ©buts de sections importantes
        pour Ã©viter que le semantic chunker ne coupe au milieu d'une unitÃ© logique.
        
        Args:
            text: Texte brut Ã  prÃ©traiter
            
        Returns:
            Texte prÃ©traitÃ© avec marqueurs de section
        """
        # Ajouter des marqueurs spÃ©ciaux pour les patterns de section X., X.Y., X.Y.Z.
        # Ces marqueurs aideront le semantic chunker Ã  respecter ces frontiÃ¨res
        lines = text.split('\n')
        processed_lines = []
        
        for line in lines:
            # DÃ©tecter les numÃ©ros de section comme X., X.Y., X.Y.Z.
            if any(pattern in line for pattern in [
                # Patterns pour dÃ©tecter les numÃ©ros de section
                # Format X.
                r'^\d+\.\s',
                # Format X.Y.
                r'^\d+\.\d+\.\s',
                # Format X.Y.Z.
                r'^\d+\.\d+\.\d+\.\s',
            ]):
                # Ajouter un marqueur spÃ©cial pour indiquer un dÃ©but de section important
                processed_lines.append(f"[SECTION_BREAK]{line}")
            else:
                processed_lines.append(line)
        
        return '\n'.join(processed_lines)
    
    def _convert_to_chunks(self, semantic_chunks: List[str], document_title: Optional[str] = None) -> List[Chunk]:
        """
        Convertit les chunks sÃ©mantiques en objets Chunk structurÃ©s.
        
        Args:
            semantic_chunks: Liste de chunks textuels gÃ©nÃ©rÃ©s par le chunker sÃ©mantique
            document_title: Titre du document
            
        Returns:
            Liste d'objets Chunk avec mÃ©tadonnÃ©es
        """
        chunks = []
        
        for i, chunk_text in enumerate(semantic_chunks):
            # Supprimer les marqueurs de section qui ont Ã©tÃ© ajoutÃ©s
            cleaned_text = chunk_text.replace("[SECTION_BREAK]", "")
            
            # DÃ©tecter la premiÃ¨re ligne pour essayer d'extraire un numÃ©ro de section
            lines = cleaned_text.split('\n')
            section_number = None
            
            # Chercher un numÃ©ro de section dans les premiÃ¨res lignes
            for line in lines[:5]:  # Regarder les 5 premiÃ¨res lignes
                # Pattern simple pour la dÃ©tection de numÃ©ro de section (peut Ãªtre amÃ©liorÃ©)
                import re
                match = re.search(r'^(\d+(?:\.\d+)*)', line)
                if match:
                    section_number = match.group(1)
                    break
            
            # CrÃ©er un objet Chunk
            chunk = Chunk(
                content=cleaned_text,
                section_number=section_number,
                document_title=document_title,
                hierarchy=self._extract_hierarchy(section_number) if section_number else None,
                parent_section=self._extract_parent_section(section_number) if section_number else None,
                chapter_title=None  # Pourrait Ãªtre extrait si nÃ©cessaire
            )
            
            chunks.append(chunk)
        
        return chunks
    
    def _extract_hierarchy(self, section_number: str) -> List[str]:
        """
        Extrait la hiÃ©rarchie Ã  partir d'un numÃ©ro de section.
        Par exemple, pour "3.4.1", retourne ["3", "3.4", "3.4.1"]
        
        Args:
            section_number: NumÃ©ro de section (ex: "3.4.1")
            
        Returns:
            Liste de numÃ©ros de section reprÃ©sentant la hiÃ©rarchie
        """
        if not section_number:
            return []
            
        parts = section_number.split('.')
        hierarchy = []
        current = ""
        
        for part in parts:
            if current:
                current += f".{part}"
            else:
                current = part
            hierarchy.append(current)
            
        return hierarchy
    
    def _extract_parent_section(self, section_number: str) -> Optional[str]:
        """
        Extrait le numÃ©ro de section parent.
        Par exemple, pour "3.4.1", retourne "3.4"
        
        Args:
            section_number: NumÃ©ro de section (ex: "3.4.1")
            
        Returns:
            NumÃ©ro de la section parente ou None
        """
        if not section_number or '.' not in section_number:
            return None
            
        parts = section_number.split('.')
        return '.'.join(parts[:-1])
    
    def chunk_text(self, text: str, document_title: Optional[str] = None) -> List[Chunk]:
        """
        DÃ©coupe le texte en chunks sÃ©mantiques intelligents, en prÃ©servant la structure du document.
        
        Args:
            text: Texte Ã  dÃ©couper
            document_title: Titre du document (optionnel)
            
        Returns:
            Liste d'objets Chunk avec mÃ©tadonnÃ©es
        """
        print("\nğŸ” DÃ©coupage sÃ©mantique du texte...")
        
        # PrÃ©traitement pour ajouter des marqueurs de section
        processed_text = self._preprocess_text_with_section_markers(text)
        
        # Utiliser le semantic chunker pour dÃ©couper le texte
        semantic_chunks = self.semantic_chunker.split_text(processed_text)
        
        print(f"ğŸ“Š Chunks sÃ©mantiques crÃ©Ã©s: {len(semantic_chunks)}")
        
        # Convertir en objets Chunk
        chunks = self._convert_to_chunks(semantic_chunks, document_title)
        
        return chunks 